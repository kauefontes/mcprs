# MCPRS: Model Context Protocol para Rust

[![Crates.io](https://img.shields.io/crates/v/mcprs)](https://crates.io/crates/mcprs)
[![Documentation](https://docs.rs/mcprs/badge.svg)](https://docs.rs/mcprs)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

MCPRS √© uma biblioteca Rust que implementa um protocolo padronizado (Model Context Protocol) para comunica√ß√£o com diversos Large Language Models (LLMs) e servi√ßos de IA. Ela fornece uma camada de abstra√ß√£o unificada que permite aos desenvolvedores interagir com diferentes APIs de IA (como OpenAI GPT, DeepSeek, etc.) de forma consistente e intercambi√°vel.

## Principais Caracter√≠sticas

- üîÑ **Interface Unificada**: Uma √∫nica API consistente para todos os modelos de IA
- üåê **M√∫ltiplos Provedores**: Suporte integrado para OpenAI e DeepSeek (facilmente extens√≠vel)
- üîå **Arquitetura Plug√°vel**: Adicione novos provedores de IA implementando a trait `AIAgent`
- üîí **Autentica√ß√£o**: Sistema de autentica√ß√£o baseado em tokens
- üí¨ **Gerenciamento de Conversas**: Armazene e gerencie hist√≥rico de conversas
- üìä **Streaming**: Suporte para respostas em streaming dos modelos
- üß™ **Testabilidade**: Abstra√ß√µes para facilitar testes com mocks

## Instala√ß√£o

Adicione MCPRS ao seu `Cargo.toml`:

```toml
[dependencies]
mcprs = "0.1.0"
```

## Guia R√°pido

### Cliente Simples

```rust
use mcprs::client::{create_mcp_message_for_agent, send_mcp_request};
use serde_json::json;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Criar uma mensagem para o agente OpenAI
    let message = create_mcp_message_for_agent(
        "openai",
        "chat",
        json!({
            "user_prompt": "Explique a linguagem Rust em poucas palavras"
        }),
    );

    // Enviar para um servidor MCP
    let response = send_mcp_request("http://localhost:3000/mcp", &message).await?;

    // Processar a resposta
    println!("Resposta: {}", response.payload["answer"]);

    Ok(())
}
```

### Servidor B√°sico

```rust
use mcprs::agent::AgentRegistry;
use mcprs::agent_openai::create_openai_agent;
use mcprs::server::run_http_server;
use std::net::SocketAddr;

#[tokio::main]
async fn main() {
    // Configurar vari√°vel de ambiente com sua chave de API
    std::env::set_var("OPENAI_API_KEY", "sua-chave-aqui");

    // Criar e configurar o registro de agentes
    let mut registry = AgentRegistry::new();
    registry.register_agent(Box::new(create_openai_agent(None)));

    // Iniciar o servidor
    let addr: SocketAddr = "127.0.0.1:3000".parse().unwrap();
    run_http_server(registry, addr).await;
}
```

### Servidor Avan√ßado com Autentica√ß√£o e Hist√≥rico

```rust
use mcprs::agent::AgentRegistry;
use mcprs::agent_openai::create_openai_agent;
use mcprs::auth::AuthConfig;
use mcprs::conversation::ConversationManager;
use mcprs::server::run_http_server_with_auth;
use std::net::SocketAddr;

#[tokio::main]
async fn main() {
    // Configurar vari√°vel de ambiente
    std::env::set_var("OPENAI_API_KEY", "sua-chave-aqui");

    // Configurar agentes
    let mut registry = AgentRegistry::new();
    registry.register_agent(Box::new(create_openai_agent(None)));

    // Configurar autentica√ß√£o
    let auth_config = AuthConfig::new();
    auth_config.add_token("token-de-acesso-seguro".to_string());

    // Configurar gerenciamento de conversas (24h de reten√ß√£o)
    let conversation_manager = ConversationManager::new(24);

    // Iniciar servidor
    let addr: SocketAddr = "127.0.0.1:3000".parse().unwrap();
    run_http_server_with_auth(registry, auth_config, conversation_manager, addr).await;
}
```

## Conceitos Principais

### Protocolo MCP

O Model Context Protocol (MCP) define um formato padronizado para mensagens trocadas entre clientes e servidores:

```rust
pub struct MCPMessage {
    pub magic: String,      // Identificador do protocolo "MCP0"
    pub version: u8,        // Vers√£o do protocolo
    pub command: String,    // Comando no formato "agente:a√ß√£o"
    pub payload: Value,     // Dados JSON da requisi√ß√£o/resposta
}
```

### Agentes de IA

Os agentes implementam a trait `AIAgent` e encapsulam a comunica√ß√£o com servi√ßos espec√≠ficos de IA:

```rust
#[async_trait]
pub trait AIAgent: Send + Sync {
    fn name(&self) -> &str;
    async fn process_request(&self, message: MCPMessage) -> Result<MCPMessage, MCPError>;
}
```

Agentes dispon√≠veis:
- **DummyAgent**: Para testes, apenas ecoa o payload recebido
- **OpenAIAgent**: Integra com a API do OpenAI (ChatGPT)
- **DeepSeekAgent**: Integra com a API DeepSeek

## Documenta√ß√£o Detalhada

### Cliente

O m√≥dulo `client` fornece fun√ß√µes para construir e enviar mensagens MCP:

```rust
// Criar uma mensagem MCP formatada corretamente
let message = create_mcp_message_for_agent("openai", "chat", payload);

// Enviar a mensagem para um servidor MCP
let response = send_mcp_request("http://exemplo.com/mcp", &message).await?;
```

### Servidor

O m√≥dulo `server` implementa um servidor HTTP que pode receber e processar mensagens MCP:

```rust
// Vers√£o b√°sica do servidor
run_http_server(registry, addr).await;

// Vers√£o avan√ßada com autentica√ß√£o e hist√≥rico
run_http_server_with_auth(registry, auth_config, conversation_manager, addr).await;
```

### Autentica√ß√£o

O m√≥dulo `auth` fornece um sistema de autentica√ß√£o baseado em tokens:

```rust
// Configura√ß√£o de tokens permitidos
let auth_config = AuthConfig::new();
auth_config.add_token("token-secreto".to_string());

// No cliente (usando reqwest)
client.post(url).bearer_auth("token-secreto").json(&message).send().await?;
```

### Conversa√ß√µes

O m√≥dulo `conversation` implementa gerenciamento de hist√≥rico de conversa√ß√µes:

```rust
// Criar um gerenciador de conversas
let manager = ConversationManager::new(24); // reten√ß√£o de 24 horas

// Criar uma nova conversa
let conversation = manager.create_conversation()?;

// Adicionar mensagens
manager.add_message_to_conversation(&conversation.id, "user", "Ol√°!")?;

// Recuperar hist√≥rico
let history = manager.get_conversation(&conversation.id);
```

### Streaming

O m√≥dulo `streaming` fornece suporte para processamento de respostas em streaming:

```rust
// Processar um stream de bytes em tokens estruturados
let token_stream = process_json_stream::<_, ResponseType>(bytes_stream).await?;

// Consumir os tokens
while let Some(Ok(token)) = token_stream.next().await {
    if token.is_finish {
        break;
    }
    println!("{}", token.content);
}
```

## Implementando um Novo Agente

Para adicionar suporte a um novo servi√ßo de IA, implemente a trait `AIAgent`:

```rust
pub struct MyNewAgent {
    pub api_key: String,
    http_client: Box<dyn HttpClient>,
}

#[async_trait]
impl AIAgent for MyNewAgent {
    fn name(&self) -> &str {
        "my-agent"
    }

    async fn process_request(&self, message: MCPMessage) -> Result<MCPMessage, MCPError> {
        // Implemente a l√≥gica de comunica√ß√£o com a API externa
        // ...

        Ok(MCPMessage::new(
            "my-agent_response",
            json!({ "answer": "Resposta processada" }),
        ))
    }
}
```

## Configura√ß√£o de Ambiente

O projeto utiliza vari√°veis de ambiente para configura√ß√µes sens√≠veis:

- `OPENAI_API_KEY` - Chave de API para o agente OpenAI
- `DEEPSEEK_API_KEY` - Chave de API para o agente DeepSeek
- `DEEPSEEK_ENDPOINT` - URL do endpoint DeepSeek (padr√£o: https://api.deepseek.ai)
- `DEEPSEEK_MODEL` - Modelo DeepSeek a ser usado (padr√£o: deepseek-chat)

## Exemplos

O reposit√≥rio inclui exemplos completos:

- **Client**: Um cliente simples para enviar requisi√ß√µes
- **Server**: Um servidor completo com autentica√ß√£o e hist√≥rico
- **Demonstrate Agents**: Exemplo que cria um servidor e envia requisi√ß√µes para testar

## Testes

A biblioteca vem com uma su√≠te de testes automatizados:

```bash
# Executar todos os testes
cargo test

# Executar testes espec√≠ficos
cargo test agent_
```

## Pr√≥ximos Passos e Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! √Åreas de melhoria incluem:

- Adicionar mais agentes de IA (Claude, Cohere, Mistral, etc.)
- Melhorar o sistema de streaming com tipagem espec√≠fica por agente
- Implementar cache de respostas
- Adicionar ferramentas (tools) para processamento avan√ßado

## Licen√ßa

Este projeto est√° licenciado sob a [Licen√ßa MIT](LICENSE).
